{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c3719e625422e6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0035cc95c2dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/opt/itmo-bigdata/hw3'\n",
    "!python3 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a64c354ee0f85e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Block #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae193dcaa730d88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Default dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a892a7b8d49fa4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T18:59:30.496263Z",
     "start_time": "2023-12-26T18:59:30.412354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/itmo-bigdata/hw3/kafka-notebook\n"
     ]
    }
   ],
   "source": [
    "%cd '/opt/itmo-bigdata/hw3/kafka-notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93305efdac766494",
   "metadata": {},
   "source": [
    "### Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a377e9537b4317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T18:59:37.121682Z",
     "start_time": "2023-12-26T18:59:37.110763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting producer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile producer.py\n",
    "import argparse\n",
    "import random\n",
    "from json import dumps\n",
    "from time import sleep\n",
    "from kafka import KafkaProducer, errors\n",
    "\n",
    "def write_data(producer, data_cnt):\n",
    "    topic = \"hw3_topic\"\n",
    "    for i in range(data_cnt):\n",
    "        device_id = random.randint(1, 10)\n",
    "        temperature = random.uniform(60, 110) + 273\n",
    "        execution_time = i * 5\n",
    "        cur_data = {\"device_id\": device_id, \"temperature\": temperature, \"execution_time\": execution_time}\n",
    "        producer.send(topic,\n",
    "                      key=dumps(device_id).encode('utf-8'),\n",
    "                      value=cur_data)\n",
    "        print(f\"Data was sent to topic [{topic}]: {cur_data}\")\n",
    "        sleep(1)\n",
    "\n",
    "def create_producer():\n",
    "    print(\"Connecting to Kafka brokers\")\n",
    "    try:\n",
    "        producer = KafkaProducer(bootstrap_servers=['kafka:9092'],\n",
    "                                 value_serializer=lambda x: dumps(x).encode('utf-8'),\n",
    "                                 acks=1)\n",
    "        print(\"Connected to Kafka\")\n",
    "        return producer\n",
    "    except errors.NoBrokersAvailable:\n",
    "        print(\"Waiting for brokers to become available\")\n",
    "        raise RuntimeError(\"Failed to connect to brokers within retry limit\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Kafka Producer\")\n",
    "    parser.add_argument(\"--message-count\", type=int, help=\"Number of messages to produce\", default=10)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    producer = create_producer()\n",
    "    write_data(producer, args.message_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a816c00dbf659c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T19:00:13.492706Z",
     "start_time": "2023-12-26T18:59:41.430719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Kafka brokers\r\n",
      "Connected to Kafka\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 9, 'temperature': 357.40012963027146, 'execution_time': 0}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 2, 'temperature': 364.9799128401146, 'execution_time': 5}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 9, 'temperature': 370.5970677553671, 'execution_time': 10}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 3, 'temperature': 378.3886575379388, 'execution_time': 15}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 7, 'temperature': 358.0674366332065, 'execution_time': 20}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 10, 'temperature': 380.6022317166541, 'execution_time': 25}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 8, 'temperature': 356.19092611032727, 'execution_time': 30}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 8, 'temperature': 367.454130692534, 'execution_time': 35}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 9, 'temperature': 338.43179639391195, 'execution_time': 40}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 5, 'temperature': 369.88929174996883, 'execution_time': 45}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 5, 'temperature': 373.51858866484656, 'execution_time': 50}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 4, 'temperature': 355.8679397336616, 'execution_time': 55}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 2, 'temperature': 339.5095990444519, 'execution_time': 60}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 3, 'temperature': 362.66978433662473, 'execution_time': 65}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 8, 'temperature': 340.9995650936915, 'execution_time': 70}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 1, 'temperature': 372.1168391717925, 'execution_time': 75}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 4, 'temperature': 335.882702729276, 'execution_time': 80}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 5, 'temperature': 351.8026958574593, 'execution_time': 85}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 7, 'temperature': 354.51131870085766, 'execution_time': 90}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 9, 'temperature': 338.38186032020025, 'execution_time': 95}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 5, 'temperature': 342.761168647805, 'execution_time': 100}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 1, 'temperature': 382.87268384161223, 'execution_time': 105}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 5, 'temperature': 381.9384910598833, 'execution_time': 110}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 7, 'temperature': 343.6707070726825, 'execution_time': 115}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 2, 'temperature': 373.8590667351317, 'execution_time': 120}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 6, 'temperature': 343.0413869515723, 'execution_time': 125}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 1, 'temperature': 367.7526013299445, 'execution_time': 130}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 9, 'temperature': 350.0400309906761, 'execution_time': 135}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 10, 'temperature': 350.47670472149656, 'execution_time': 140}\r\n",
      "Data was sent to topic [hw3_topic]: {'device_id': 1, 'temperature': 373.90300371878936, 'execution_time': 145}\r\n"
     ]
    }
   ],
   "source": [
    "!python3 producer.py --message-count 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b2f183fd8000f0",
   "metadata": {},
   "source": [
    "\n",
    "### Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed70714f3e6faee7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T21:30:14.698906Z",
     "start_time": "2023-12-25T21:30:14.697681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting consumer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile consumer.py\n",
    "import argparse\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "def create_consumer(max_messages=None):\n",
    "    print(\"Connecting to Kafka brokers\")\n",
    "    consumer = KafkaConsumer(\"hw3_topic\",\n",
    "                             group_id=\"itmo_hw3_group\",\n",
    "                             bootstrap_servers='kafka:9092',\n",
    "                             auto_offset_reset='earliest',\n",
    "                             enable_auto_commit=True)\n",
    "\n",
    "    message_count = 0\n",
    "    for message in consumer:\n",
    "        print(message)\n",
    "\n",
    "        message_count += 1\n",
    "\n",
    "        if max_messages and message_count >= max_messages:\n",
    "            break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Kafka Consumer Example\")\n",
    "    parser.add_argument(\"--message-limit\", type=int, help=\"Maximum number of messages to consume\", default=None)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    create_consumer(max_messages=args.message_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f5f47e92517c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T21:30:19.117333Z",
     "start_time": "2023-12-25T21:30:16.841890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Kafka brokers\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=0, timestamp=1703539775770, timestamp_type=0, key=b'5', value=b'{\"device_id\": 5, \"temperature\": 378.8648169030971, \"execution_time\": 0}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=71, serialized_header_size=-1)\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=1, timestamp=1703539776772, timestamp_type=0, key=b'6', value=b'{\"device_id\": 6, \"temperature\": 368.30924691389487, \"execution_time\": 5}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=72, serialized_header_size=-1)\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=2, timestamp=1703539777774, timestamp_type=0, key=b'2', value=b'{\"device_id\": 2, \"temperature\": 367.55649140998236, \"execution_time\": 10}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=73, serialized_header_size=-1)\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=3, timestamp=1703539778778, timestamp_type=0, key=b'8', value=b'{\"device_id\": 8, \"temperature\": 364.72706033537463, \"execution_time\": 15}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=73, serialized_header_size=-1)\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=4, timestamp=1703539779783, timestamp_type=0, key=b'6', value=b'{\"device_id\": 6, \"temperature\": 365.4685412219744, \"execution_time\": 20}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=72, serialized_header_size=-1)\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=5, timestamp=1703539780786, timestamp_type=0, key=b'4', value=b'{\"device_id\": 4, \"temperature\": 355.23828862098406, \"execution_time\": 25}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=73, serialized_header_size=-1)\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=6, timestamp=1703539781789, timestamp_type=0, key=b'2', value=b'{\"device_id\": 2, \"temperature\": 371.29977934694836, \"execution_time\": 30}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=73, serialized_header_size=-1)\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=7, timestamp=1703539782795, timestamp_type=0, key=b'3', value=b'{\"device_id\": 3, \"temperature\": 369.2200390614406, \"execution_time\": 35}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=72, serialized_header_size=-1)\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=8, timestamp=1703539783799, timestamp_type=0, key=b'7', value=b'{\"device_id\": 7, \"temperature\": 347.34340211741454, \"execution_time\": 40}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=73, serialized_header_size=-1)\r\n",
      "ConsumerRecord(topic='hw3_topic', partition=0, offset=9, timestamp=1703539784803, timestamp_type=0, key=b'6', value=b'{\"device_id\": 6, \"temperature\": 377.02934322006263, \"execution_time\": 45}', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=73, serialized_header_size=-1)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 consumer.py --message-limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82317c26e857ae7",
   "metadata": {},
   "source": [
    "### Apache Flink job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3664c23a745373d4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T21:30:24.235193Z",
     "start_time": "2023-12-25T21:30:23.596764Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p tmp/checkpoints/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ba506c35c075b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T21:30:28.180019Z",
     "start_time": "2023-12-25T21:30:28.173558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing flink_job1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flink_job1.py\n",
    "from argparse import ArgumentParser\n",
    "from pyflink.common import SimpleStringSchema\n",
    "from pyflink.common.typeinfo import Types, RowTypeInfo\n",
    "from pyflink.common.watermark_strategy import WatermarkStrategy\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.datastream.connectors import DeliveryGuarantee\n",
    "from pyflink.datastream.connectors.kafka import KafkaSource, KafkaOffsetsInitializer, KafkaSink, KafkaRecordSerializationSchema\n",
    "from pyflink.datastream.formats.json import JsonRowDeserializationSchema\n",
    "from pyflink.datastream.functions import MapFunction\n",
    "from pyflink.datastream.checkpoint_config import CheckpointingMode\n",
    "\n",
    "\n",
    "def python_data_stream_example(checkpoint_dir):\n",
    "    env = StreamExecutionEnvironment.get_execution_environment()\n",
    "    env.set_parallelism(1)\n",
    "\n",
    "    env.enable_checkpointing(10000)  # checkpoint every 10000 ms\n",
    "    env.get_checkpoint_config().set_checkpointing_mode(CheckpointingMode.EXACTLY_ONCE)\n",
    "    env.get_checkpoint_config().set_min_pause_between_checkpoints(500)\n",
    "    env.get_checkpoint_config().set_max_concurrent_checkpoints(1)\n",
    "    env.get_checkpoint_config().set_checkpoint_storage_dir(checkpoint_dir)\n",
    "\n",
    "    type_info: RowTypeInfo = Types.ROW_NAMED([\"device_id\", \"temperature\", \"execution_time\"],\n",
    "                                             [Types.LONG(), Types.DOUBLE(), Types.INT()])\n",
    "\n",
    "    json_row_schema = JsonRowDeserializationSchema.builder().type_info(type_info).build()\n",
    "\n",
    "    source = KafkaSource.builder() \\\n",
    "        .set_bootstrap_servers('kafka:9092') \\\n",
    "        .set_topics('hw3_topic') \\\n",
    "        .set_group_id('pyflink-e2e-source') \\\n",
    "        .set_starting_offsets(KafkaOffsetsInitializer.earliest()) \\\n",
    "        .set_value_only_deserializer(json_row_schema) \\\n",
    "        .build()\n",
    "\n",
    "    sink = KafkaSink.builder() \\\n",
    "        .set_bootstrap_servers('kafka:9092') \\\n",
    "        .set_record_serializer(KafkaRecordSerializationSchema.builder()\n",
    "                               .set_topic('hw3_preprocessed_topic')\n",
    "                               .set_value_serialization_schema(SimpleStringSchema())\n",
    "                               .build()\n",
    "                               ) \\\n",
    "        .set_delivery_guarantee(DeliveryGuarantee.AT_LEAST_ONCE) \\\n",
    "        .build()\n",
    "\n",
    "    ds = env.from_source(source, WatermarkStrategy.no_watermarks(), \"Kafka Source\")\n",
    "    ds.map(TemperatureFunction(), Types.STRING()) \\\n",
    "        .sink_to(sink)\n",
    "    env.execute_async(\"Devices preprocessing\")\n",
    "\n",
    "\n",
    "class TemperatureFunction(MapFunction):\n",
    "\n",
    "    def map(self, value):\n",
    "        device_id, temperature, execution_time = value\n",
    "        return str({\"device_id\": device_id, \"temperature\": temperature - 273, \"execution_time\": execution_time})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description=\"Flink Job with Checkpointing\")\n",
    "    parser.add_argument(\"--checkpoint_dir\", type=str, help=\"Directory for saving checkpoints\", default='file:///opt/pyflink/tmp/checkpoints/logs')\n",
    "    args = parser.parse_args()\n",
    "    python_data_stream_example(args.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fa2ff733619c4f",
   "metadata": {},
   "source": [
    "Job execution:\n",
    "\n",
    "```commandline\n",
    "docker-compose exec jobmanager ./bin/flink run -py /opt/pyflink/flink_job1.py -d \n",
    "```\n",
    "Screen log result:\n",
    "![job](images/block1_job.png)\n",
    "\n",
    "Screen Apache Flink Example:\n",
    "![flink](images/block1_flink.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387850e9a15d2af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Block #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef609ba-0452-4760-b830-9b8ecb4c5c73",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%writefile flink_job2.py\n",
    "from argparse import ArgumentParser\n",
    "from pyflink.common import SimpleStringSchema, Time\n",
    "from pyflink.common.typeinfo import Types\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.datastream.connectors import DeliveryGuarantee\n",
    "from pyflink.datastream.connectors.kafka import KafkaSource, KafkaOffsetsInitializer, KafkaSink, KafkaRecordSerializationSchema\n",
    "from pyflink.datastream.formats.json import JsonRowDeserializationSchema\n",
    "from pyflink.datastream.functions import MapFunction\n",
    "from pyflink.datastream.checkpoint_config import CheckpointingMode\n",
    "from pyflink.datastream.window import TumblingEventTimeWindows, SlidingEventTimeWindows, EventTimeSessionWindows\n",
    "from pyflink.common.watermark_strategy import WatermarkStrategy\n",
    "from pyflink.common.time import Duration\n",
    "\n",
    "\n",
    "class FormatTemperature(MapFunction):\n",
    "    def map(self, value):\n",
    "        return \"max_temp: {}\".format(value[1])\n",
    "\n",
    "\n",
    "def python_data_stream_example(checkpoint_dir, window_type):\n",
    "    env = StreamExecutionEnvironment.get_execution_environment()\n",
    "    env.set_parallelism(1)\n",
    "    env.enable_checkpointing(10000)\n",
    "    env.get_checkpoint_config().set_checkpointing_mode(CheckpointingMode.EXACTLY_ONCE)\n",
    "    env.get_checkpoint_config().set_min_pause_between_checkpoints(500)\n",
    "    env.get_checkpoint_config().set_max_concurrent_checkpoints(1)\n",
    "    env.get_checkpoint_config().set_checkpoint_storage_dir(checkpoint_dir)\n",
    "\n",
    "    type_info = Types.ROW_NAMED([\"device_id\", \"temperature\", \"execution_time\"],\n",
    "                                [Types.LONG(), Types.DOUBLE(), Types.INT()])\n",
    "\n",
    "    json_row_schema = JsonRowDeserializationSchema.builder().type_info(type_info).build()\n",
    "\n",
    "    source = KafkaSource.builder() \\\n",
    "        .set_bootstrap_servers('kafka:9092') \\\n",
    "        .set_topics('hw3_topic') \\\n",
    "        .set_group_id('pyflink-e2e-source') \\\n",
    "        .set_starting_offsets(KafkaOffsetsInitializer.earliest()) \\\n",
    "        .set_value_only_deserializer(json_row_schema) \\\n",
    "        .build()\n",
    "\n",
    "    sink = KafkaSink.builder() \\\n",
    "        .set_bootstrap_servers('kafka:9092') \\\n",
    "        .set_record_serializer(KafkaRecordSerializationSchema.builder()\n",
    "                               .set_topic('hw3_preprocessed_topic')\n",
    "                               .set_value_serialization_schema(SimpleStringSchema())\n",
    "                               .build()\n",
    "                               ) \\\n",
    "        .set_delivery_guarantee(DeliveryGuarantee.AT_LEAST_ONCE) \\\n",
    "        .build()\n",
    "\n",
    "    watermark_strategy = WatermarkStrategy.for_bounded_out_of_orderness(Duration.of_seconds(5)) \\\n",
    "        .with_timestamp_assigner(lambda event, timestamp: event[2])\n",
    "\n",
    "    ds = env.from_source(source, watermark_strategy, \"Kafka Source\")\n",
    "\n",
    "    if window_type == \"tumbling\":\n",
    "        ds = ds.key_by(lambda value: value[0]) \\\n",
    "            .window(TumblingEventTimeWindows.of(Time.seconds(15))) \\\n",
    "            .reduce(lambda a, b: a if a[1] > b[1] else b) \\\n",
    "            .map(FormatTemperature(), output_type=Types.STRING())\n",
    "    elif window_type == \"sliding\":\n",
    "        ds = ds.key_by(lambda value: value[0]) \\\n",
    "            .window(SlidingEventTimeWindows.of(Time.seconds(15), Time.seconds(5))) \\\n",
    "            .reduce(lambda a, b: a if a[1] > b[1] else b) \\\n",
    "            .map(FormatTemperature(), output_type=Types.STRING())\n",
    "    elif window_type == \"session\":\n",
    "        ds = ds.key_by(lambda value: value[0]) \\\n",
    "            .window(EventTimeSessionWindows.with_gap(Time.seconds(10))) \\\n",
    "            .reduce(lambda a, b: a if a[1] > b[1] else b) \\\n",
    "            .map(FormatTemperature(), output_type=Types.STRING())\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported window type: {}\".format(window_type))\n",
    "\n",
    "    ds.sink_to(sink)\n",
    "    env.execute_async(\"Devices preprocessing\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description=\"Flink Job with Different Window Types\")\n",
    "    parser.add_argument(\"--checkpoint_dir\", type=str, help=\"Directory for saving checkpoints\",\n",
    "                        default='file:///opt/pyflink/tmp/checkpoints/logs')\n",
    "    parser.add_argument(\"--window_type\", type=str, help=\"Type of window to apply (tumbling, sliding, session)\",\n",
    "                        default='tumbling')\n",
    "    args = parser.parse_args()\n",
    "    print(args.window_type)\n",
    "    python_data_stream_example(args.checkpoint_dir, args.window_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39da6fb282f0eb0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Job executions:\n",
    "```commandline\n",
    "docker-compose exec jobmanager ./bin/flink run -py /opt/pyflink/flink_job2.py --window_type 'tumbling' -d \n",
    "```\n",
    "```commandline\n",
    "docker-compose exec jobmanager ./bin/flink run -py /opt/pyflink/flink_job2.py --window_type 'sliding' -d \n",
    "```\n",
    "```commandline\n",
    "docker-compose exec jobmanager ./bin/flink run -py /opt/pyflink/flink_job2.py --window_type 'session' -d \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eca878-0015-4299-a649-1a5e21356ce4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Block #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52d2421251e79ef",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:08:39.474397Z",
     "start_time": "2023-12-26T19:08:39.466770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting backoff_consumer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile backoff_consumer.py\n",
    "import time\n",
    "import random\n",
    "from functools import wraps\n",
    "import argparse\n",
    "from kafka import KafkaConsumer\n",
    "from json import loads\n",
    "\n",
    "def backoff(tries, delay, backoff_factor=1.5):\n",
    "    \"\"\"\n",
    "    Backoff decorator that retries the function upon failure.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            ntries, ndelay = tries, delay\n",
    "            while ntries > 1:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}, retrying in {ndelay} seconds...\")\n",
    "                    time.sleep(ndelay)\n",
    "                    ntries -= 1\n",
    "                    ndelay *= backoff_factor\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@backoff(tries=10, delay=2)\n",
    "def message_handler(value):\n",
    "    \"\"\"\n",
    "    Process the message and simulate an error with a 30% probability.\n",
    "    \"\"\"\n",
    "    if random.random() < 0.3:\n",
    "        raise ValueError(\"Simulated processing error\")\n",
    "    print(f\"Processed message: {value}\")\n",
    "\n",
    "def connect_kafka_consumer():\n",
    "    try:\n",
    "        consumer = KafkaConsumer(\"hw3_topic\",\n",
    "                                 group_id=\"itmo_hw3_group\",\n",
    "                                 bootstrap_servers='kafka:9092',\n",
    "                                 auto_offset_reset='earliest',\n",
    "                                 enable_auto_commit=True,\n",
    "                                 value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
    "        print(\"Connected to Kafka\")\n",
    "        return consumer\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to Kafka: {e}\")\n",
    "        raise\n",
    "\n",
    "def create_consumer(max_messages=None):\n",
    "    consumer = connect_kafka_consumer()\n",
    "    print(\"Consumer setup complete. Listening for messages...\")\n",
    "    message_count = 0\n",
    "    for message in consumer:\n",
    "        try:\n",
    "            message_handler(message.value)\n",
    "            message_count += 1\n",
    "            if max_messages and message_count >= max_messages:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing message: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Kafka Consumer with Backoff for Message Handling\")\n",
    "    parser.add_argument(\"--message-limit\", type=int, help=\"Maximum number of messages to consume\", default=None)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    create_consumer(max_messages=args.message_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77780acb9eac72ba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Example of consumer operation with dynamic backoff (increased waiting time for each subsequent attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7155548eb26e2b3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:09:27.591198Z",
     "start_time": "2023-12-26T19:08:47.684571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Kafka\r\n",
      "Consumer setup complete. Listening for messages...\r\n",
      "Processed message: {'device_id': 9, 'temperature': 357.40012963027146, 'execution_time': 0}\r\n",
      "Processed message: {'device_id': 2, 'temperature': 364.9799128401146, 'execution_time': 5}\r\n",
      "Processed message: {'device_id': 9, 'temperature': 370.5970677553671, 'execution_time': 10}\r\n",
      "Processed message: {'device_id': 3, 'temperature': 378.3886575379388, 'execution_time': 15}\r\n",
      "Processed message: {'device_id': 7, 'temperature': 358.0674366332065, 'execution_time': 20}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Processed message: {'device_id': 10, 'temperature': 380.6022317166541, 'execution_time': 25}\r\n",
      "Processed message: {'device_id': 8, 'temperature': 356.19092611032727, 'execution_time': 30}\r\n",
      "Processed message: {'device_id': 8, 'temperature': 367.454130692534, 'execution_time': 35}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Error: Simulated processing error, retrying in 3.0 seconds...\r\n",
      "Error: Simulated processing error, retrying in 4.5 seconds...\r\n",
      "Processed message: {'device_id': 9, 'temperature': 338.43179639391195, 'execution_time': 40}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Error: Simulated processing error, retrying in 3.0 seconds...\r\n",
      "Error: Simulated processing error, retrying in 4.5 seconds...\r\n",
      "Processed message: {'device_id': 5, 'temperature': 369.88929174996883, 'execution_time': 45}\r\n",
      "Processed message: {'device_id': 5, 'temperature': 373.51858866484656, 'execution_time': 50}\r\n",
      "Processed message: {'device_id': 4, 'temperature': 355.8679397336616, 'execution_time': 55}\r\n",
      "Processed message: {'device_id': 2, 'temperature': 339.5095990444519, 'execution_time': 60}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Processed message: {'device_id': 3, 'temperature': 362.66978433662473, 'execution_time': 65}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Processed message: {'device_id': 8, 'temperature': 340.9995650936915, 'execution_time': 70}\r\n",
      "Processed message: {'device_id': 1, 'temperature': 372.1168391717925, 'execution_time': 75}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Processed message: {'device_id': 4, 'temperature': 335.882702729276, 'execution_time': 80}\r\n",
      "Processed message: {'device_id': 5, 'temperature': 351.8026958574593, 'execution_time': 85}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Processed message: {'device_id': 7, 'temperature': 354.51131870085766, 'execution_time': 90}\r\n",
      "Processed message: {'device_id': 9, 'temperature': 338.38186032020025, 'execution_time': 95}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Processed message: {'device_id': 5, 'temperature': 342.761168647805, 'execution_time': 100}\r\n",
      "Processed message: {'device_id': 1, 'temperature': 382.87268384161223, 'execution_time': 105}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Processed message: {'device_id': 5, 'temperature': 381.9384910598833, 'execution_time': 110}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Processed message: {'device_id': 7, 'temperature': 343.6707070726825, 'execution_time': 115}\r\n",
      "Processed message: {'device_id': 2, 'temperature': 373.8590667351317, 'execution_time': 120}\r\n",
      "Processed message: {'device_id': 6, 'temperature': 343.0413869515723, 'execution_time': 125}\r\n",
      "Error: Simulated processing error, retrying in 2 seconds...\r\n",
      "Processed message: {'device_id': 1, 'temperature': 367.7526013299445, 'execution_time': 130}\r\n",
      "Processed message: {'device_id': 9, 'temperature': 350.0400309906761, 'execution_time': 135}\r\n",
      "Processed message: {'device_id': 10, 'temperature': 350.47670472149656, 'execution_time': 140}\r\n",
      "Processed message: {'device_id': 1, 'temperature': 373.90300371878936, 'execution_time': 145}\r\n"
     ]
    }
   ],
   "source": [
    "!python3 backoff_consumer.py --message-limit 30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
